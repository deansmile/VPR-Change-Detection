wandb: Tracking run with wandb version 0.17.7
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
Using cache found in /home/ds5725/.cache/torch/hub/facebookresearch_dinov2_main
A matching Triton is not available, some optimizations will not be enabled.
Error caught was: No module named 'triton'
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
start program
{
    "model": {
        "name": "dino2 + cross_attention",
        "dino-model": "dinov2_vits14",
        "layer1": 11,
        "facet1": "query",
        "facet2": "query",
        "num-heads": 1,
        "dropout-rate": 0.1,
        "target-shp-row": 504,
        "target-shp-col": 504,
        "num-blocks": 1,
        "freeze-dino": true,
        "unfreeze-dino-last-n-layer": 0
    },
    "optimizer": {
        "epochs": 100,
        "warmup-epoch": 10,
        "learn-rate": 0.0001,
        "loss-weight": true,
        "lr-scheduler": "cosine",
        "grad-scaler": true
    },
    "dataset": {
        "batch-size": 4,
        "num-workers": 4,
        "dataset": "VL_CMU_CD",
        "hflip-prob": 0.5,
        "diff-augment": false
    },
    "evaluation": {
        "trainset": 0
    },
    "wandb": {
        "project": "",
        "name": "",
        "output-path": "/scratch/ds5725/alvpr/Robust-Scene-Change-Detection/src/output/2025-04-27.17-34-40",
        "save-checkpoint-freq": 10
    },
    "environment": {
        "dry": true,
        "seed": 123,
        "verbose": true,
        "device": "cuda"
    }
}
final text_encoder_type: bert-base-uncased
Unfreeze fusion_layers
get CMU dataset
initialize our train dataset
changed object text description
initialize our train dataset
changed object text description
initialize our test dataset
changed object text description
epochs: 100
     ===== running 0 epoch =====
     2025-04-27.17-35-05
     
     *** train one epoch ***
after set grad
after prog
start loop
     input_1:  torch.Size([4, 3, 504, 504])
     input_2:  torch.Size([4, 3, 504, 504])
     targets:  torch.Size([4, 504, 504])
     caption:  ['scaffolding. green tree.', 'large vehicle. green tree.', 'sign. ', 'text. bare tree. bare bush.']
DINOv2 feature shape from img_1: torch.Size([4, 384, 36, 36])
DINOv2 feature shape from img_2: torch.Size([4, 384, 36, 36])
[Registration] Strategies - 3D: 0, 2D: 4, Identity: 0
Traceback (most recent call last):
  File "/scratch/ds5725/alvpr/Robust-Scene-Change-Detection/src/scripts/train.py", line 470, in <module>
    main(args)
  File "/scratch/ds5725/alvpr/Robust-Scene-Change-Detection/src/scripts/train.py", line 277, in main
    loss, data_inds, batch_losses, train_time = train_one_epoch(
  File "/scratch/ds5725/alvpr/Robust-Scene-Change-Detection/src/scripts/train.py", line 113, in train_one_epoch
    outputs = model(input_1, input_2, caption)  # (n, 504, 504, 2)
  File "/ext3/miniconda3/envs/cyws3d/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/ext3/miniconda3/envs/cyws3d/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File "/ext3/miniconda3/envs/cyws3d/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/scratch/ds5725/alvpr/Robust-Scene-Change-Detection/src/./models/CD_model.py", line 223, in forward
    dino_feat_1_0, dino_feat_2_0 = self.feature_register(batch_info, dino_feat_1_0, dino_feat_2_0)
  File "/ext3/miniconda3/envs/cyws3d/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/scratch/ds5725/alvpr/Robust-Scene-Change-Detection/CYWS-3D/modules/registeration_module.py", line 181, in forward
    image1_2d, image2_2d, trasform_points_1_to_2_2d, transform_points_2_to_1_2d = self.register_features(slice_batch_given_bool_array(batch, reg_2d), image1[reg_2d], image2[reg_2d], "2d")
  File "/scratch/ds5725/alvpr/Robust-Scene-Change-Detection/CYWS-3D/modules/registeration_module.py", line 158, in register_features
    image1_warped_onto_image2, image2_warped_onto_image1, trasform_points_1_to_2, transform_points_2_to_1 = self.register_2d_features(
  File "/scratch/ds5725/alvpr/Robust-Scene-Change-Detection/CYWS-3D/modules/registeration_module.py", line 102, in register_2d_features
    M_1_to_2.append(batch["transfm2d_1_to_2"][i])
KeyError: 'transfm2d_1_to_2'
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /scratch/ds5725/alvpr/Robust-Scene-Change-Detection/src/output/2025-04-27.17-34-40/wandb/offline-run-20250427_133441-0sgg2suf
wandb: Find logs at: ./output/2025-04-27.17-34-40/wandb/offline-run-20250427_133441-0sgg2suf/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
