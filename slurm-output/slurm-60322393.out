wandb: WARNING Unable to verify login in offline mode.
wandb: Tracking run with wandb version 0.19.10
wandb: W&B syncing is set to `offline` in this directory. Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
Using cache found in /home/ds5725/.cache/torch/hub/facebookresearch_dinov2_main
A matching Triton is not available, some optimizations will not be enabled.
Error caught was: No module named 'triton'
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
start program
{
    "model": {
        "name": "dino2 + cross_attention",
        "dino-model": "dinov2_vits14",
        "layer1": 11,
        "facet1": "query",
        "facet2": "query",
        "num-heads": 1,
        "dropout-rate": 0.1,
        "target-shp-row": 504,
        "target-shp-col": 504,
        "num-blocks": 1,
        "freeze-dino": true,
        "unfreeze-dino-last-n-layer": 0
    },
    "optimizer": {
        "epochs": 100,
        "early-stop": 5,
        "warmup-epoch": 10,
        "learn-rate": 0.0001,
        "loss-weight": true,
        "lr-scheduler": "cosine",
        "grad-scaler": true
    },
    "dataset": {
        "batch-size": 2,
        "num-workers": 4,
        "dataset": "Combined",
        "hflip-prob": 0.5,
        "diff-augment": false
    },
    "evaluation": {
        "trainset": 0
    },
    "wandb": {
        "project": "",
        "name": "",
        "output-path": "/scratch/ds5725/alvpr/Robust-Scene-Change-Detection/src/output/2025-05-09.14-03-50",
        "save-checkpoint-freq": 10
    },
    "environment": {
        "dry": true,
        "seed": 123,
        "verbose": true,
        "device": "cuda"
    }
}
LORA added to the encoder
final text_encoder_type: bert-base-uncased
Unfreeze fusion_layers
get combined dataset
initialize cmu dataset
initialize our train dataset
initialize cmu dataset
initialize our train dataset
initialize cmu dataset
initialize our test dataset
epochs: 100
     ===== running 0 epoch =====
     2025-05-09.14-04-14
     
     *** train one epoch ***
after set grad
after prog
start loop
Warning: No caption found for 00000623
Warning: No caption found for 00000482
Warning: No caption found for 00000068
Warning: No caption found for 00000490
Warning: No caption found for 00000534
Warning: No caption found for 00000178
Warning: No caption found for 00000747
Warning: No caption found for 00000115
Warning: No caption found for 00000427
Warning: No caption found for 00000569
Warning: No caption found for 00000300
Warning: No caption found for 00000721
Warning: No caption found for 00000411
Warning: No caption found for 00000309
Warning: No caption found for 00000319
Warning: No caption found for 00000252
Warning: No caption found for 00000534
Warning: No caption found for 00000198
Warning: No caption found for 00000072
Warning: No caption found for 00000042
Warning: No caption found for 00000525
Warning: No caption found for 00000288
Warning: No caption found for 00000534
Warning: No caption found for 00000706
Warning: No caption found for 00000106
Warning: No caption found for 00000044
Warning: No caption found for 00000289
Warning: No caption found for 00000658
Warning: No caption found for 00000003
Warning: No caption found for 00000094
Warning: No caption found for 00000679
Warning: No caption found for 00000212
Warning: No caption found for 00000224
Warning: No caption found for 00000601
Warning: No caption found for 00000093
Warning: No caption found for 00000762
Warning: No caption found for 00000733
Warning: No caption found for 00000637
Warning: No caption found for 00000174
Warning: No caption found for 00000741
Warning: No caption found for 00000419
Warning: No caption found for 00000460
Warning: No caption found for 00000755
Warning: No caption found for 00000713
Warning: No caption found for 00000527
Warning: No caption found for 00000279
Warning: No caption found for 00000384
Warning: No caption found for 00000560
Warning: No caption found for 00000682
Warning: No caption found for 00000056
Warning: No caption found for 00000633
Warning: No caption found for 00000649
Warning: No caption found for 00000384
Warning: No caption found for 00000389
Warning: No caption found for 00000388
Warning: No caption found for 00000613
Warning: No caption found for 00000359
Warning: No caption found for 00000096
Warning: No caption found for 00000475
Warning: No caption found for 00000141
Warning: No caption found for 00000289
Warning: No caption found for 00000475
Warning: No caption found for 00000060
Warning: No caption found for 00000006
Warning: No caption found for 00000036
Warning: No caption found for 00000545
Warning: No caption found for 00000086
Warning: No caption found for 00000458
Warning: No caption found for 00000029
Warning: No caption found for 00000183
Warning: No caption found for 00000025
Warning: No caption found for 00000271
Warning: No caption found for 00000444
Warning: No caption found for 00000312
Warning: No caption found for 00000473
Warning: No caption found for 00000351
Warning: No caption found for 00000373
Warning: No caption found for 00000387
Warning: No caption found for 00000339
Warning: No caption found for 00000102
Warning: No caption found for 00000754
Warning: No caption found for 00000149
Warning: No caption found for 00000464
Warning: No caption found for 00000723
Warning: No caption found for 00000024
Warning: No caption found for 00000655
Warning: No caption found for 00000603
Warning: No caption found for 00000422
Warning: No caption found for 00000128
Warning: No caption found for 00000610
Warning: No caption found for 00000761
Warning: No caption found for 00000514
Warning: No caption found for 00000489
Warning: No caption found for 00000341
Warning: No caption found for 00000085
Warning: No caption found for 00000452
Warning: No caption found for 00000181
Warning: No caption found for 00000370
Warning: No caption found for 00000489
Warning: No caption found for 00000099
Warning: No caption found for 00000313
Warning: No caption found for 00000249
Warning: No caption found for 00000514
Warning: No caption found for 00000531
Warning: No caption found for 00000103
Warning: No caption found for 00000120
Warning: No caption found for 00000548
Warning: No caption found for 00000438
Warning: No caption found for 00000623
Warning: No caption found for 00000375
Warning: No caption found for 00000607
Warning: No caption found for 00000176
Warning: No caption found for 00000166
Warning: No caption found for 00000171
Warning: No caption found for 00000153
Warning: No caption found for 00000034
Warning: No caption found for 00000204
Warning: No caption found for 00000242
Warning: No caption found for 00000091
Warning: No caption found for 00000210
Warning: No caption found for 00000132
Warning: No caption found for 00000016
Warning: No caption found for 00000682
     input_1:  torch.Size([2, 3, 504, 504])
     input_2:  torch.Size([2, 3, 504, 504])
     targets:  torch.Size([2, 504, 504])
     caption:  ['', 'scaffolding. green covering. orange traffic cone. green tree.']
     output:  torch.Size([2, 504, 504, 2]) -> torch.Size([2, 2, 504, 504])
     Train Epoch: [0/9870]	Loss: 0.579739
     Train Epoch: [20/9870]	Loss: 0.564798
     Train Epoch: [40/9870]	Loss: 0.807535
     Train Epoch: [60/9870]	Loss: 0.751033
     Train Epoch: [80/9870]	Loss: 0.587663
     Train Epoch: [100/9870]	Loss: 0.686241
     Train Epoch: [120/9870]	Loss: 0.691651
     Train Epoch: [140/9870]	Loss: 0.481725
     Train Epoch: [160/9870]	Loss: 0.582604
     Train Epoch: [180/9870]	Loss: 0.656668
     Train Epoch: [200/9870]	Loss: 0.716252
Traceback (most recent call last):
  File "/scratch/ds5725/alvpr/Robust-Scene-Change-Detection/src/scripts/train.py", line 475, in <module>
    main(args)
  File "/scratch/ds5725/alvpr/Robust-Scene-Change-Detection/src/scripts/train.py", line 282, in main
    loss, data_inds, batch_losses, train_time = train_one_epoch(
  File "/scratch/ds5725/alvpr/Robust-Scene-Change-Detection/src/scripts/train.py", line 113, in train_one_epoch
    outputs = model(input_1, input_2, caption)  # (n, 504, 504, 2)
  File "/ext3/miniconda3/envs/rscd/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/ext3/miniconda3/envs/rscd/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File "/ext3/miniconda3/envs/rscd/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/scratch/ds5725/alvpr/Robust-Scene-Change-Detection/src/./models/CD_model.py", line 220, in forward
    dino_feat_1_0 = self.grounding_dino.improve_dino_feature(dino_feat_1_0, caption)
  File "/scratch/ds5725/alvpr/Robust-Scene-Change-Detection/grounding_dino/groundingdino/models/GroundingDINO/groundingdino.py", line 272, in improve_dino_feature
    ) = generate_masks_with_special_tokens_and_transfer_map(
  File "/scratch/ds5725/alvpr/Robust-Scene-Change-Detection/grounding_dino/groundingdino/models/GroundingDINO/bertwarper.py", line 266, in generate_masks_with_special_tokens_and_transfer_map
    if captions is not None:
NameError: name 'captions' is not defined
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /scratch/ds5725/alvpr/Robust-Scene-Change-Detection/src/output/2025-05-09.14-03-50/wandb/offline-run-20250509_100351-y7bk31fw[0m
[1;34mwandb[0m: Find logs at: [1;35moutput/2025-05-09.14-03-50/wandb/offline-run-20250509_100351-y7bk31fw/logs[0m
